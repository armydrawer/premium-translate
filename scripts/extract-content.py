#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–µ—Ä–µ–≤–æ–¥–∏–º–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ markdown —Ñ–∞–π–ª–æ–≤
–°–æ–∑–¥–∞–µ—Ç JSON/YAML —Ñ–∞–π–ª—ã –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —á–µ—Ä–µ–∑ SimpleLocalize
"""

import os
import json
import yaml
import frontmatter
import re
from pathlib import Path


def extract_translatable_content(markdown_content, file_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥–∏–º—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ markdown —Ñ–∞–π–ª–∞"""
    
    # –ü–∞—Ä—Å–∏–º frontmatter
    post = frontmatter.loads(markdown_content)
    
    translatable_data = {
        'file_path': file_path,
        'frontmatter': {},
        'content_blocks': []
    }
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥–∏–º—ã–µ –ø–æ–ª—è –∏–∑ frontmatter
    frontmatter_fields = ['title', 'description', 'summary', 'excerpt']
    for field in frontmatter_fields:
        if field in post.metadata:
            translatable_data['frontmatter'][field] = post.metadata[field]
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –±–ª–æ–∫–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
    content = post.content
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º
    sections = re.split(r'(^#{1,6}\s+.*$)', content, flags=re.MULTILINE)
    
    block_id = 0
    current_heading = None
    
    for section in sections:
        section = section.strip()
        if not section:
            continue
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
        if re.match(r'^#{1,6}\s+', section):
            current_heading = section
            translatable_data['content_blocks'].append({
                'id': f'block_{block_id}',
                'type': 'heading',
                'content': section,
                'context': file_path
            })
            block_id += 1
        else:
            # –†–∞–∑–±–∏–≤–∞–µ–º –æ–±—ã—á–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –∞–±–∑–∞—Ü—ã
            paragraphs = [p.strip() for p in section.split('\n\n') if p.strip()]
            
            for paragraph in paragraphs:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏ –∫–æ–¥–∞
                if paragraph.startswith('```') or paragraph.startswith('    '):
                    translatable_data['content_blocks'].append({
                        'id': f'block_{block_id}',
                        'type': 'code',
                        'content': paragraph,
                        'translate': False,
                        'context': f"{file_path} - {current_heading or 'root'}"
                    })
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏—Ö –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ)
                elif re.match(r'^!\[.*\]\(.*\)$', paragraph.strip()):
                    translatable_data['content_blocks'].append({
                        'id': f'block_{block_id}',
                        'type': 'image',
                        'content': paragraph,
                        'translate': False,
                        'context': f"{file_path} - {current_heading or 'root'}"
                    })
                else:
                    # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
                    translatable_data['content_blocks'].append({
                        'id': f'block_{block_id}',
                        'type': 'text',
                        'content': paragraph,
                        'translate': True,
                        'context': f"{file_path} - {current_heading or 'root'}"
                    })
                
                block_id += 1
    
    return translatable_data


def process_ru_files():
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ markdown —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ ru/"""
    
    ru_path = Path('ru')
    translations_path = Path('translations')
    translations_path.mkdir(exist_ok=True)
    
    all_translations = {}
    files_structure = {}
    
    # –û–±—Ö–æ–¥–∏–º –≤—Å–µ .md —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ ru/
    for md_file in ru_path.rglob('*.md'):
        relative_path = str(md_file.relative_to(ru_path))
        print(f"üìÑ Processing: {relative_path}")
        
        try:
            with open(md_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥–∏–º—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
            translatable = extract_translatable_content(content, relative_path)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞
            files_structure[relative_path] = {
                'blocks_count': len(translatable['content_blocks']),
                'has_frontmatter': bool(translatable['frontmatter']),
                'original_file': str(md_file)
            }
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            file_key = relative_path.replace('/', '_').replace('.md', '')
            
            # Frontmatter
            if translatable['frontmatter']:
                for field, value in translatable['frontmatter'].items():
                    key = f"{file_key}_frontmatter_{field}"
                    all_translations[key] = value
            
            # –ö–æ–Ω—Ç–µ–Ω—Ç–Ω—ã–µ –±–ª–æ–∫–∏
            for block in translatable['content_blocks']:
                if block.get('translate', True):
                    key = f"{file_key}_{block['id']}"
                    all_translations[key] = block['content']
                    
        except Exception as e:
            print(f"‚ùå Error processing {md_file}: {e}")
            continue
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –¥–ª—è SimpleLocalize
    json_path = translations_path / 'ru' / 'documentation.json'
    json_path.parent.mkdir(exist_ok=True)
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(all_translations, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ Saved {len(all_translations)} translation keys to {json_path}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º YAML –∫–∞–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—É
    yaml_path = translations_path / 'ru' / 'docs-content.yml'
    with open(yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(all_translations, f, allow_unicode=True, default_flow_style=False)
    
    print(f"‚úÖ Saved YAML version to {yaml_path}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Å–±–æ—Ä–∫–∏
    structure_path = translations_path / 'files-structure.json'
    with open(structure_path, 'w', encoding='utf-8') as f:
        json.dump(files_structure, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ Saved file structure to {structure_path}")
    
    return len(all_translations)


if __name__ == '__main__':
    print("üîÑ Extracting translatable content from Russian documentation...")
    
    if not Path('ru').exists():
        print("‚ùå Directory 'ru' not found!")
        exit(1)
    
    keys_count = process_ru_files()
    print(f"üéØ Extraction complete! {keys_count} translation keys prepared.")
    print("üì§ Files are ready for SimpleLocalize processing.")
